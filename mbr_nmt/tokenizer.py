def default_tokenizer(sentence):
    return sentence.split(" ")
